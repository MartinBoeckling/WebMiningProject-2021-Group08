{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT Sentiment Analysis.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ceea8727bf7f4729aae382389d06f305":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bf300e592ed54427a2798ecfb335fd16","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_18a300df0b1f498aae9b89a77310ddae","IPY_MODEL_46142a1232d64532931abf55761fe6ba"]}},"bf300e592ed54427a2798ecfb335fd16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"18a300df0b1f498aae9b89a77310ddae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0298f09a19de45b690f220db3e854e8a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1ab6193e45c94a81a1a6198906cae3ef"}},"46142a1232d64532931abf55761fe6ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_85d1a0766d6b4429b65c58c3872fa3a6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:00&lt;00:00, 10.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3dd5f474e4e94273af04d6349b0d9112"}},"0298f09a19de45b690f220db3e854e8a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1ab6193e45c94a81a1a6198906cae3ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"85d1a0766d6b4429b65c58c3872fa3a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3dd5f474e4e94273af04d6349b0d9112":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"20a143828d6c41819dbaa266af1558be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_544e325f7aad4642b8313b6155529a3b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d7211bd029f84094b7713f6712a2746e","IPY_MODEL_7357b51de4e54af59fb8e0711f1e8e1c"]}},"544e325f7aad4642b8313b6155529a3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7211bd029f84094b7713f6712a2746e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3c7cc6238b99437bbaebed6ba50fa915","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_45817ac03f4e4340b58d087694f35843"}},"7357b51de4e54af59fb8e0711f1e8e1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_87abba732741457394dff852dade26a7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:02&lt;00:00, 107kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa92aac8eddf4f1fb58eedba3bb54f8b"}},"3c7cc6238b99437bbaebed6ba50fa915":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"45817ac03f4e4340b58d087694f35843":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87abba732741457394dff852dade26a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aa92aac8eddf4f1fb58eedba3bb54f8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f319b86fa9cd4dff87dcaebc6e0e48a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3896f958fc414f6b8c3236acd117c31f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a003d23abe7a4c9cafba21a593f40e5b","IPY_MODEL_68d0d6f0972142e3ac1073b628a03ab2"]}},"3896f958fc414f6b8c3236acd117c31f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a003d23abe7a4c9cafba21a593f40e5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e9fa1dec9f524c0fb7eeb3aac12b65ca","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b67a2b38a7da4f7bb78398784d0db4e5"}},"68d0d6f0972142e3ac1073b628a03ab2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_18a7d34b0d7a49018d420887035d6f0c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:01&lt;00:00, 361kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5f9c2df2d8a64fd0936e2b2ea9b82176"}},"e9fa1dec9f524c0fb7eeb3aac12b65ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b67a2b38a7da4f7bb78398784d0db4e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"18a7d34b0d7a49018d420887035d6f0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5f9c2df2d8a64fd0936e2b2ea9b82176":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"975b1613c8e34e039665dfb01e95ec13":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4e05ccbcf20c4ea99dd9c0d964933872","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d23cf5b1aff84f7ebb56775c71d705c0","IPY_MODEL_3816fd6ed1e8431582837e6e08b1eaeb"]}},"4e05ccbcf20c4ea99dd9c0d964933872":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d23cf5b1aff84f7ebb56775c71d705c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7df37541690349619d33c4c69e7d8ef6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3da42134df764d16b78c9633bc6cebce"}},"3816fd6ed1e8431582837e6e08b1eaeb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_88c7c5a5e33942fb8c2872215221e961","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:01&lt;00:00, 25.1B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0aa901ccf1a249c0bc18a428d16ceb30"}},"7df37541690349619d33c4c69e7d8ef6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3da42134df764d16b78c9633bc6cebce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88c7c5a5e33942fb8c2872215221e961":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0aa901ccf1a249c0bc18a428d16ceb30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78383557ba754adf9f033441879a3051":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_82b3aab2d3ca4dc58ef312b9b4705e78","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_82fb0eb72ae74c05a3eb9a2455e50f90","IPY_MODEL_9078f4fa4b2945a195de5ec25769d275"]}},"82b3aab2d3ca4dc58ef312b9b4705e78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"82fb0eb72ae74c05a3eb9a2455e50f90":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3925768e2bbf42bab43e477c655b60fa","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1101adf510454f58bf3337533a4ed042"}},"9078f4fa4b2945a195de5ec25769d275":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0d49f1792f0c4287986682891889cadc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:13&lt;00:00, 31.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dd83b3dc4e7745ceaac8fb1c8aa4184d"}},"3925768e2bbf42bab43e477c655b60fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1101adf510454f58bf3337533a4ed042":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d49f1792f0c4287986682891889cadc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dd83b3dc4e7745ceaac8fb1c8aa4184d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"JLM3B9J_7nnC"},"source":["# **BERT Sentiment analysis**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6gV23NDS70M3"},"source":["## Notebook preparation"]},{"cell_type":"markdown","metadata":{"id":"k6U47pJV8Vni"},"source":["### Setup connection to Google drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"STwulDom7mtc","executionInfo":{"status":"ok","timestamp":1623313207978,"user_tz":-120,"elapsed":23522,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"6c568040-f1e8-4192-f8b9-95d633fd8f7d"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCGsDKcP8zg2","executionInfo":{"status":"ok","timestamp":1623313207979,"user_tz":-120,"elapsed":10,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"30939c98-8f17-4385-d58f-03471e8ad8fa"},"source":["%cd '/content/drive/My Drive/Web Mining/'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Web Mining\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_znIC68dTIuB"},"source":["### install relevant packages"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHoi7pKMTLIF","executionInfo":{"status":"ok","timestamp":1623313216192,"user_tz":-120,"elapsed":8219,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"cbc9afc7-fcf8-48d6-f59e-34de184d1e44"},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 7.5MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 30.2MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 32.4MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zx8iX5r5a3fM"},"source":["### import relevant libraries"]},{"cell_type":"code","metadata":{"id":"mAYYPbhHa9Y2","executionInfo":{"status":"ok","timestamp":1623313223029,"user_tz":-120,"elapsed":6841,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["import os\n","import torch\n","import re\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from collections import Counter, defaultdict\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader, RandomSampler\n","import torch.nn.functional as F"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7mXJqPJs8f5u"},"source":["### setup gpu for training if it is available"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cruSnxpiAKu3","executionInfo":{"status":"ok","timestamp":1623313223030,"user_tz":-120,"elapsed":14,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"1d914664-4227-4319-a37b-029df102569b"},"source":["# Check if a GPU can be used\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not assign CPU\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vk7L0m9j4bzZ"},"source":["### Define run settings of notebook"]},{"cell_type":"markdown","metadata":{"id":"3r01Q56a7QXm"},"source":["Four different settings can be changed for the data preparation and training of the current notebook:\n","\n","\n","* Specify BERT Model (tested on: **bert_base_uncased**)\n","* Split lyrics with sliding window\n","* Specify Dataset\n","* Preprocess lyrics tags (will only be used for the dataset with commas for line breaks)"]},{"cell_type":"code","metadata":{"id":"9QBufedp48ws","executionInfo":{"status":"ok","timestamp":1623313223030,"user_tz":-120,"elapsed":8,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["# specify name of model\n","pretrained_model_name = 'bert-base-uncased'\n","\n","# define if lyrics should be splitted with sliding window to prevent reduction of tokens\n","split_lyrics = True\n","\n","# specify dataset that will be used for training\n","file_name = 'Classes_Dataset/all_songs_lyrics_comma_classes.csv' # Classes_Dataset/all_songs_preprocessed_classes.csv\n","\n","# preprocess lyrics tags (if dataset is included with comma)\n","if file_name == 'Classes_Dataset/all_songs_preprocessed_classes.csv':\n","  preprocess_lyrics = False # Does not need to be changed as in this dataset preprocessing was already done\n","else:\n","  preprocess_lyrics = True # Can be set to false, but was not tested\n","\n","# define how many epochs we want to train\n","EPOCHS = 5\n","\n","# define how many classes can be chosen\n","num_classes = 3"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htUutPVlaSSr","executionInfo":{"status":"ok","timestamp":1623313223031,"user_tz":-120,"elapsed":8,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"b2159256-5888-4179-841e-3ab72264357f"},"source":["# define random settings for reproducability\n","random_seed = 46\n","torch.manual_seed(random_seed)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fd42b14bdf0>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"HhT7u8q79wcw"},"source":["## Data Preparation\n"]},{"cell_type":"markdown","metadata":{"id":"n0mtzvyZ_PIE"},"source":["### Load data"]},{"cell_type":"markdown","metadata":{"id":"6DHnbWyhInLz"},"source":["Print basic structure of dataframe to get overall understanding of the data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JSgru6898_cn","executionInfo":{"status":"ok","timestamp":1623313223853,"user_tz":-120,"elapsed":827,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"9961243b-352d-45d0-bce3-4cdaf86bed31"},"source":["data = pd.read_csv(file_name)\n","\n","if num_classes == 2:\n","  data = data[['lyrics', 'sentiment_2classes']]\n","  data = data.dropna()\n","elif num_classes == 3:\n","  data = data[['lyrics', 'sentiment_3classes']]\n","else:\n","  raise ValueError(f'Specify num_classes variable instead of {num_classes} to either 2 or 3')\n","\n","data.columns = ['lyrics', 'sentiment']\n","\n","print(data.columns)\n","print(data.head(5))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Index(['lyrics', 'sentiment'], dtype='object')\n","                                              lyrics  sentiment\n","0  [Chorus: The Charmaines],Let's make this Chris...          0\n","1  Come over baby whole lot of shakin' goin' on,,...          2\n","2  [Verse 1],I sit alone in my bedroom,Starin' at...          2\n","3  [Intro],Ooh,,[Verse 1],Can you feel me when I ...          1\n","4  [Verse 1],One day when I came home at lunchtim...          2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vGpS_3sIVFug"},"source":["### Replace information parts within lyrics\n","\n","\n","> Parts in which f.e. Chorus or Verse is marked within dataset (New part will be marked with an point, linebreaks with a comma\n","\n"]},{"cell_type":"code","metadata":{"id":"IhG1fUnrVHa6","executionInfo":{"status":"ok","timestamp":1623313224671,"user_tz":-120,"elapsed":822,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["def preprocess(lyrics):\n","  lyrics = re.sub(r'\\[.*?\\]', '.', lyrics) # replace Information brackets with point to mark end of logical part in a song\n","  lyrics = re.sub(r'^(,*\\.,*)', '', lyrics) # replace dots and commas at beginning of song\n","  return re.sub(r'(,*\\.,*)', '.', lyrics) # replace sequence of commas before and after a point with a single point\n","\n","if preprocess_lyrics is True:\n","  data['lyrics_pre'] = data.lyrics.apply(preprocess)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9y9UJ8sTR8NG"},"source":["### define sliding window\n","Idea is to not truncate lyrics as important information might get missed\n","\n","\n","> Sliding window is defined by a window size of 200 words and incorporation 50 words from before to add context to sliding window\n","\n"]},{"cell_type":"code","metadata":{"id":"wJhrKOlbSvVz","executionInfo":{"status":"ok","timestamp":1623313224672,"user_tz":-120,"elapsed":5,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["# define method for sliding window\n","def get_split(lyrics):\n","  data = []\n","  partial = []\n","  if len(lyrics.split())//150 >0:\n","    n = len(lyrics.split())//150\n","  else: \n","    n = 1\n","  for w in range(n):\n","    if w == 0:\n","      partial = lyrics.split()[:200]\n","      data.append(\" \".join(partial))\n","    else:\n","      partial = lyrics.split()[w*150:w*150 + 200]\n","      data.append(\" \".join(partial))\n","  return data"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"yddPIYXxR7oZ","executionInfo":{"status":"ok","timestamp":1623313233101,"user_tz":-120,"elapsed":8433,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["# check if lyrics will be splitted\n","if split_lyrics is True:\n","  if preprocess_lyrics is True:\n","    data['lyrics_split'] = data['lyrics_pre'].apply(get_split)\n","  else:\n","    data['lyrics_split'] = data['lyrics'].apply(get_split)\n","  # define list for reconstructing dataframe\n","  train = []\n","  label = []\n","  index =[]\n","  # iterate through list to split list in one column into multiple rows\n","  for idx,row in data.iterrows():\n","    for element in row['lyrics_split']:\n","      train.append(element)\n","      label.append(row['sentiment'])\n","      index.append(idx)\n","  data = pd.DataFrame({'lyrics': train, 'sentiment': label})\n","else:\n","  data = data[['lyrics', 'sentiment']]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"VhxhHPKjfwYZ","executionInfo":{"status":"ok","timestamp":1623313233103,"user_tz":-120,"elapsed":36,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"ebdc946c-396d-41ae-be2f-548e9c22569c"},"source":["data"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lyrics</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Let's make this Christmas mean something this ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Come over baby whole lot of shakin' goin' on,,...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I sit alone in my bedroom,Starin' at the walls...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Ooh.Can you feel me when I think about you?,Wi...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>One day when I came home at lunchtime,I heard ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21683</th>\n","      <td>see it,She'll make the first move, smooth, int...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21684</th>\n","      <td>(down, down).Baby, whatever you want, girl, yo...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21685</th>\n","      <td>That lipstick on your collar, well, it ain't m...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21686</th>\n","      <td>When you get caught in the rain,With nowhere t...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21687</th>\n","      <td>Hey,Hey.I'm addicted 끊임없이,말을 걸어주는 나의 aespa (Oh...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21688 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  lyrics  sentiment\n","0      Let's make this Christmas mean something this ...          0\n","1      Come over baby whole lot of shakin' goin' on,,...          2\n","2      I sit alone in my bedroom,Starin' at the walls...          2\n","3      Ooh.Can you feel me when I think about you?,Wi...          1\n","4      One day when I came home at lunchtime,I heard ...          2\n","...                                                  ...        ...\n","21683  see it,She'll make the first move, smooth, int...          1\n","21684  (down, down).Baby, whatever you want, girl, yo...          1\n","21685  That lipstick on your collar, well, it ain't m...          1\n","21686  When you get caught in the rain,With nowhere t...          1\n","21687  Hey,Hey.I'm addicted 끊임없이,말을 걸어주는 나의 aespa (Oh...          1\n","\n","[21688 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"ffVa5RehbR65"},"source":["### split data in train, validation and test dataset\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pDY-E-Qmamlk","executionInfo":{"status":"ok","timestamp":1623313233105,"user_tz":-120,"elapsed":18,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"7f9bd83f-4144-4bf0-f4bc-90ce822edefc"},"source":["# ratio for training and test data split\n","ratio_test = 0.2\n","# define random seed to get same result for the training and test data\n","data_train, data_test, target_train, target_test = train_test_split(data['lyrics'], data['sentiment'], test_size=ratio_test, random_state=random_seed, shuffle=True)\n","data_val, data_test, target_val, target_test = train_test_split(data_test, target_test, test_size=0.5, random_state=random_seed, shuffle=True)\n","\n","# Check splits\n","print(f'Train size: {len(target_train)}')\n","print(f'Test size: {len(target_test)}')\n","print(f'Validation size: {len(target_val)}')\n","# Check balance of different subsets\n","print(10*'-')\n","if num_classes == 2:\n","  print(f'Train size positive: {np.sum(target_train==1)}')\n","  print(f'Train size neutral: {np.sum(target_train==2)}')\n","  print(f'Train size negative: {np.sum(target_train==0)}')\n","  print(f'Test size positive: {np.sum(target_test==1)}')\n","  print(f'Test size neutral: {np.sum(target_test==2)}')\n","  print(f'Test size negative: {np.sum(target_test==0)}')\n","  print(f'Validation size positive: {np.sum(target_val==1)}')\n","  print(f'Validation size neutral: {np.sum(target_val==2)}')\n","  print(f'Validation size negative: {np.sum(target_val==0)}')\n","elif num_classes == 3:\n","  print(f'Train size positive: {np.sum(target_train==2)}')\n","  print(f'Train size neutral: {np.sum(target_train==1)}')\n","  print(f'Train size negative: {np.sum(target_train==0)}')\n","  print(f'Test size positive: {np.sum(target_test==2)}')\n","  print(f'Test size neutral: {np.sum(target_test==1)}')\n","  print(f'Test size negative: {np.sum(target_test==0)}')\n","  print(f'Validation size positive: {np.sum(target_val==2)}')\n","  print(f'Validation size neutral: {np.sum(target_val==1)}')\n","  print(f'Validation size negative: {np.sum(target_val==0)}')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Train size: 17350\n","Test size: 2169\n","Validation size: 2169\n","----------\n","Train size positive: 5843\n","Train size neutral: 5576\n","Train size negative: 5931\n","Test size positive: 771\n","Test size neutral: 657\n","Test size negative: 741\n","Validation size positive: 724\n","Validation size neutral: 712\n","Validation size negative: 733\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dy-5g20_Yn5g"},"source":["### Tokenizer\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YPBurCrIY7Ia"},"source":["#### Load Tokenizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":230,"referenced_widgets":["ceea8727bf7f4729aae382389d06f305","bf300e592ed54427a2798ecfb335fd16","18a300df0b1f498aae9b89a77310ddae","46142a1232d64532931abf55761fe6ba","0298f09a19de45b690f220db3e854e8a","1ab6193e45c94a81a1a6198906cae3ef","85d1a0766d6b4429b65c58c3872fa3a6","3dd5f474e4e94273af04d6349b0d9112","20a143828d6c41819dbaa266af1558be","544e325f7aad4642b8313b6155529a3b","d7211bd029f84094b7713f6712a2746e","7357b51de4e54af59fb8e0711f1e8e1c","3c7cc6238b99437bbaebed6ba50fa915","45817ac03f4e4340b58d087694f35843","87abba732741457394dff852dade26a7","aa92aac8eddf4f1fb58eedba3bb54f8b","f319b86fa9cd4dff87dcaebc6e0e48a1","3896f958fc414f6b8c3236acd117c31f","a003d23abe7a4c9cafba21a593f40e5b","68d0d6f0972142e3ac1073b628a03ab2","e9fa1dec9f524c0fb7eeb3aac12b65ca","b67a2b38a7da4f7bb78398784d0db4e5","18a7d34b0d7a49018d420887035d6f0c","5f9c2df2d8a64fd0936e2b2ea9b82176","975b1613c8e34e039665dfb01e95ec13","4e05ccbcf20c4ea99dd9c0d964933872","d23cf5b1aff84f7ebb56775c71d705c0","3816fd6ed1e8431582837e6e08b1eaeb","7df37541690349619d33c4c69e7d8ef6","3da42134df764d16b78c9633bc6cebce","88c7c5a5e33942fb8c2872215221e961","0aa901ccf1a249c0bc18a428d16ceb30"]},"id":"pHAKNequdU3N","executionInfo":{"status":"ok","timestamp":1623313236637,"user_tz":-120,"elapsed":3546,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"a9218bf1-b7c3-463c-d889-875d3822274c"},"source":["# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name, do_lower_case=True)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Loading BERT tokenizer...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ceea8727bf7f4729aae382389d06f305","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20a143828d6c41819dbaa266af1558be","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f319b86fa9cd4dff87dcaebc6e0e48a1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"975b1613c8e34e039665dfb01e95ec13","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_xREKKy2Zfwv"},"source":["#### Build Dataset for training"]},{"cell_type":"code","metadata":{"id":"v9xCTG8pjgy8","executionInfo":{"status":"ok","timestamp":1623313236640,"user_tz":-120,"elapsed":13,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["# Construct DataLoader class to transform data to DataLoader object\n","class LyricsDataset(Dataset):\n","\n","  def __init__(self, lyrics, labels, tokenizer, max_len):\n","    self.lyrics = lyrics\n","    self.labels = labels\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","\n","  def __len__(self):\n","    return len(self.lyrics)\n","\n","  def __getitem__(self, idx):\n","    lyrics = str(self.lyrics[idx])\n","    label = self.labels[idx]\n","    encoding = self.tokenizer.encode_plus(\n","      lyrics,\n","      add_special_tokens=True, # Add '[CLS]' and '[SEP]' and [PAD]\n","      max_length=self.max_len, # Pad & truncate all texts\n","      pad_to_max_length=True,\n","      return_token_type_ids=False,\n","      return_attention_mask=True, # Construct attention masks\n","      return_tensors='pt', # Return pytorch tensors\n","    )\n","    return {\n","      'lyrics_text': lyrics,\n","      'input_ids': encoding['input_ids'].flatten(),\n","      'attention_mask': encoding['attention_mask'].flatten(),\n","      'labels': torch.tensor(label, dtype=torch.long)\n","    }"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDpYOAmUmdGy","executionInfo":{"status":"ok","timestamp":1623313236641,"user_tz":-120,"elapsed":12,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["# which help us to customizing data loading order and do automatic batching\n","def create_data_loader(X, Y, tokenizer, max_len, batch_size, num_workers=2, sampler = None):\n","  ds = LyricsDataset(\n","    lyrics=np.array(X),\n","    labels=np.array(Y),\n","    tokenizer=tokenizer,\n","    max_len=max_len\n","  )\n","  if sampler!=None:\n","    sampler = sampler(ds)\n","\n","  return DataLoader(\n","    ds,\n","    batch_size=batch_size,\n","    num_workers=num_workers,\n","    sampler = sampler\n","  )"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"bJ0i68eSjs-7","executionInfo":{"status":"ok","timestamp":1623313236644,"user_tz":-120,"elapsed":14,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["MAX_LEN = 256\n","BATCH_SIZE = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order.\n","train_data_loader = create_data_loader(data_train, target_train, tokenizer, MAX_LEN, BATCH_SIZE, sampler = RandomSampler) # Select batches randomly\n","val_data_loader = create_data_loader(data_val, target_val, tokenizer, MAX_LEN, BATCH_SIZE, sampler = RandomSampler) # Pull out batches sequentially.\n","test_data_loader = create_data_loader(data_test, target_test, tokenizer, MAX_LEN, BATCH_SIZE, sampler = RandomSampler) # Pull out batches sequentially."],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AvhfAYaib-fh"},"source":["## Modelling"]},{"cell_type":"markdown","metadata":{"id":"1FL0mslicFuC"},"source":["### Load model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["78383557ba754adf9f033441879a3051","82b3aab2d3ca4dc58ef312b9b4705e78","82fb0eb72ae74c05a3eb9a2455e50f90","9078f4fa4b2945a195de5ec25769d275","3925768e2bbf42bab43e477c655b60fa","1101adf510454f58bf3337533a4ed042","0d49f1792f0c4287986682891889cadc","dd83b3dc4e7745ceaac8fb1c8aa4184d"]},"id":"QoUmbyOU_7KP","executionInfo":{"status":"ok","timestamp":1623313260147,"user_tz":-120,"elapsed":23516,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"ee284a36-0c91-4019-b57b-7eda8a32150e"},"source":["# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = AutoModelForSequenceClassification.from_pretrained(\n","    pretrained_model_name,\n","    num_labels = num_classes, # output labels specified in the num_classes variable\n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the specified device\n","model.to(device)"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78383557ba754adf9f033441879a3051","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0FnnTNmdByH-","executionInfo":{"status":"ok","timestamp":1623313260147,"user_tz":-120,"elapsed":14,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"90fe048f-d08b-470f-bc04-0be16df1821f"},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (3, 768)\n","classifier.bias                                                 (3,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2ngDu4LYcVRZ"},"source":["### Define optimizer"]},{"cell_type":"code","metadata":{"id":"s4Rk4nrmB6YS","executionInfo":{"status":"ok","timestamp":1623313260148,"user_tz":-120,"elapsed":9,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5,\n","                  eps = 1e-8\n","                )"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTmMGA_OCWqT","executionInfo":{"status":"ok","timestamp":1623313260148,"user_tz":-120,"elapsed":8,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["# Total number of training steps is [number of batches] x [number of epochs]. \n","total_steps = len(train_data_loader) * EPOCHS\n","\n","# Create the learning rate scheduler, here we use a linear scheduler with no warmup steps\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","\n","# Define our loss function\n","loss_fn = nn.CrossEntropyLoss().to(device)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssQe3wUJB-By","executionInfo":{"status":"ok","timestamp":1623313260149,"user_tz":-120,"elapsed":9,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["# Training\n","def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n","  model.train()\n","  total_train_accuracy = 0\n","  total_train_loss = 0\n","  losses = []\n","  correct_predictions = 0\n","  for step, batch in enumerate(data_loader):\n","    if step % 40 == 0 and not step == 0:\n","       print('Batch: {}  of  {}'.format(step, len(data_loader)))\n","    input_ids = batch[\"input_ids\"].to(device)\n","    attention_mask = batch[\"attention_mask\"].to(device)\n","    labels = batch[\"labels\"].to(device)\n","    model.zero_grad()\n","    outputs = model(\n","      input_ids=input_ids,\n","      token_type_ids=None,\n","      attention_mask=attention_mask,\n","      labels=labels\n","    )\n","    loss = outputs[0]\n","    total_train_loss += loss.item()\n","    loss.backward()\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","    optimizer.step()\n","    scheduler.step()\n","    optimizer.zero_grad()\n","\n","    logits = outputs[1].detach().cpu().numpy()\n","    label_ids = labels.to('cpu').numpy()\n","    total_train_accuracy += flat_accuracy(logits, label_ids)\n","  # Calculate the average loss over all of the batches.\n","  avg_train_accuracy = total_train_accuracy / len(data_loader)\n","  avg_train_loss = total_train_loss / len(data_loader) \n","  return avg_train_accuracy, avg_train_loss"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"9TunoAn7MY4m","executionInfo":{"status":"ok","timestamp":1623313260149,"user_tz":-120,"elapsed":8,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"GL5_k6jq-I91","executionInfo":{"status":"ok","timestamp":1623313260150,"user_tz":-120,"elapsed":9,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["# Evaluation\n","def eval_model(model, data_loader, loss_fn, device, n_examples):\n","  model.eval()\n","  total_eval_accuracy = 0\n","  total_eval_loss = 0\n","  nb_eval_steps = 0\n","  losses = []\n","  correct_predictions = 0\n","  with torch.no_grad():\n","    for batch in data_loader:\n","      input_ids = batch[\"input_ids\"].to(device)\n","      attention_mask = batch[\"attention_mask\"].to(device)\n","      labels = batch[\"labels\"].to(device)\n","      outputs = model(\n","        input_ids=input_ids,\n","        token_type_ids=None,\n","        attention_mask=attention_mask,\n","        labels=labels\n","      )\n","      total_eval_loss += outputs[0].item()\n","      logits = outputs[1].detach().cpu().numpy()\n","      label_ids = labels.to('cpu').numpy()\n","      total_eval_accuracy += flat_accuracy(logits, label_ids)\n","\n","  avg_val_accuracy = total_eval_accuracy / len(data_loader)\n","  avg_val_loss = total_eval_loss / len(data_loader)\n","  return avg_val_accuracy, avg_val_loss"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Eo3UGD1CGzC","executionInfo":{"status":"ok","timestamp":1623315516970,"user_tz":-120,"elapsed":2256463,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"9bd87a49-8643-4d71-d500-3028e3432a35"},"source":["%%time\n","\n","from collections import defaultdict\n","history = defaultdict(list)\n","best_accuracy = 0\n","for epoch in range(EPOCHS):\n","  print('Epoch: {}/{}'.format(epoch+1, EPOCHS))\n","  print('-' * 10)\n","  train_acc, train_loss = train_epoch(\n","    model,\n","    train_data_loader,\n","    loss_fn,\n","    optimizer,\n","    device,\n","    scheduler,\n","    len(data_train)\n","  )\n","  print('Train loss: {}, Accuracy: {}'.format(train_loss, train_acc))\n","  val_acc, val_loss = eval_model(\n","    model,\n","    val_data_loader,\n","    loss_fn,\n","    device,\n","    len(data_val)\n","  )\n","  print('Val loss: {}, Accuracy: {}'.format(val_loss, val_acc))\n","  print()\n","  history['train_acc'].append(train_acc)\n","  history['train_loss'].append(train_loss)\n","  history['val_acc'].append(val_acc)\n","  history['val_loss'].append(val_loss)\n","\n","  model_save_name = 'model_epoch' + str(epoch+1) + '.bin'\n","  torch.save(model.state_dict(), model_save_name)\n","\n","  if val_acc > best_accuracy:\n","    print('Epoch: ', str(epoch+1))\n","    torch.save(model.state_dict(), 'best_model_state.bin')\n","    best_accuracy = val_acc"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Epoch: 1/5\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Batch: 40  of  543\n","Batch: 80  of  543\n","Batch: 120  of  543\n","Batch: 160  of  543\n","Batch: 200  of  543\n","Batch: 240  of  543\n","Batch: 280  of  543\n","Batch: 320  of  543\n","Batch: 360  of  543\n","Batch: 400  of  543\n","Batch: 440  of  543\n","Batch: 480  of  543\n","Batch: 520  of  543\n","Train loss: 1.0340359198893412, Accuracy: 0.4541896869244936\n"],"name":"stdout"},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss: 0.9869430748855367, Accuracy: 0.5102757352941176\n","\n","Epoch:  1\n","Epoch: 2/5\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Batch: 40  of  543\n","Batch: 80  of  543\n","Batch: 120  of  543\n","Batch: 160  of  543\n","Batch: 200  of  543\n","Batch: 240  of  543\n","Batch: 280  of  543\n","Batch: 320  of  543\n","Batch: 360  of  543\n","Batch: 400  of  543\n","Batch: 440  of  543\n","Batch: 480  of  543\n","Batch: 520  of  543\n","Train loss: 0.9561085727333364, Accuracy: 0.5279696132596685\n"],"name":"stdout"},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss: 0.9677411615848541, Accuracy: 0.5234558823529412\n","\n","Epoch:  2\n","Epoch: 3/5\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Batch: 40  of  543\n","Batch: 80  of  543\n","Batch: 120  of  543\n","Batch: 160  of  543\n","Batch: 200  of  543\n","Batch: 240  of  543\n","Batch: 280  of  543\n","Batch: 320  of  543\n","Batch: 360  of  543\n","Batch: 400  of  543\n","Batch: 440  of  543\n","Batch: 480  of  543\n","Batch: 520  of  543\n","Train loss: 0.8162270877681823, Accuracy: 0.6263620319214241\n"],"name":"stdout"},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss: 0.9925625350545434, Accuracy: 0.5425735294117647\n","\n","Epoch:  3\n","Epoch: 4/5\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Batch: 40  of  543\n","Batch: 80  of  543\n","Batch: 120  of  543\n","Batch: 160  of  543\n","Batch: 200  of  543\n","Batch: 240  of  543\n","Batch: 280  of  543\n","Batch: 320  of  543\n","Batch: 360  of  543\n","Batch: 400  of  543\n","Batch: 440  of  543\n","Batch: 480  of  543\n","Batch: 520  of  543\n","Train loss: 0.6372326280420876, Accuracy: 0.7278813689379987\n"],"name":"stdout"},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss: 1.1080659347421982, Accuracy: 0.5228125\n","\n","Epoch: 5/5\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Batch: 40  of  543\n","Batch: 80  of  543\n","Batch: 120  of  543\n","Batch: 160  of  543\n","Batch: 200  of  543\n","Batch: 240  of  543\n","Batch: 280  of  543\n","Batch: 320  of  543\n","Batch: 360  of  543\n","Batch: 400  of  543\n","Batch: 440  of  543\n","Batch: 480  of  543\n","Batch: 520  of  543\n","Train loss: 0.5103043796662687, Accuracy: 0.7974409146715777\n"],"name":"stdout"},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Val loss: 1.2033220748690998, Accuracy: 0.5243198529411766\n","\n","CPU times: user 36min 49s, sys: 15.1 s, total: 37min 4s\n","Wall time: 37min 36s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HCRn7M-NIeAp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623315534948,"user_tz":-120,"elapsed":17999,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"a4194571-9238-4647-c5cf-ac8ab8a86a4a"},"source":["test_acc, test_loss = eval_model(\n","  model,\n","  test_data_loader,\n","  loss_fn,\n","  device,\n","  len(data_test)\n",")\n","print(f'Testing Accuracy: {test_acc.item()}')\n","print(f'Testing Loss: {test_loss}')"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Testing Accuracy: 0.5567463235294118\n","Testing Loss: 1.1627932567806805\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1hT_VxFrKdxl","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1623315534949,"user_tz":-120,"elapsed":23,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"1e2848d7-9120-4911-ec89-4a22c7a0f6df"},"source":["# Plot the accuracy for training and validation set\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","plt.plot(history['train_acc'], label='train accuracy')\n","plt.plot(history['val_acc'], label='validation accuracy')\n","plt.title('Training history')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.xticks(np.arange(1, 6, 1.0))\n","plt.ylim([0, 1]);"],"execution_count":27,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"-zaRmxdYMnhR","executionInfo":{"status":"ok","timestamp":1623315535371,"user_tz":-120,"elapsed":429,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"444c3556-a650-49dd-9505-9ad8678d3c3c"},"source":["# Plot the accuracy for training and validation set\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","plt.plot(history['train_loss'], label='train loss')\n","plt.plot(history['val_loss'], label='validation loss')\n","plt.title('Training history')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.xticks(np.arange(0, 5, 1.0))\n","plt.ylim([0, 1]);"],"execution_count":28,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"42jUf3EdNgrY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623315543079,"user_tz":-120,"elapsed":7713,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"884ccfaf-2153-4c84-e66b-490b05dceb97"},"source":["# How to save model\n","output_dir = f'./save_model_{pretrained_model_name}'\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","#Load a trained model and vocabulary that you have fine-tuned\n","# model = BertForSequenceClassification.from_pretrained(output_dir)\n","# tokenizer = BertTokenizer.from_pretrained(output_dir)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Saving model to ./save_model_bert-base-uncased\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('./save_model_bert-base-uncased/tokenizer_config.json',\n"," './save_model_bert-base-uncased/special_tokens_map.json',\n"," './save_model_bert-base-uncased/vocab.txt',\n"," './save_model_bert-base-uncased/added_tokens.json',\n"," './save_model_bert-base-uncased/tokenizer.json')"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"JtgXLjdjM3Cw","executionInfo":{"status":"ok","timestamp":1623315543081,"user_tz":-120,"elapsed":11,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}}},"source":["def get_predictions(model, data_loader):\n","    model = model.eval()\n","    \n","    lyrics_texts = []\n","    predictions = []\n","    prediction_probs = []\n","    real_values = []\n","\n","    with torch.no_grad():\n","        for d in data_loader:\n","\n","            texts = d[\"lyrics_text\"]\n","            input_ids = d[\"input_ids\"].to(device)\n","            attention_mask = d[\"attention_mask\"].to(device)\n","            targets = d[\"labels\"].to(device)\n","            \n","            outputs = model(input_ids=input_ids, token_type_ids=None, attention_mask=attention_mask, labels = targets)\n","\n","            loss = outputs[0]\n","            logits = outputs[1]\n","            \n","            _, preds = torch.max(outputs[1], dim=1)\n","\n","            probs = F.softmax(outputs[1], dim=1)\n","\n","            lyrics_texts.extend(texts)\n","            predictions.extend(preds)\n","            prediction_probs.extend(probs)\n","            real_values.extend(targets)\n","\n","    predictions = torch.stack(predictions).cpu()\n","    prediction_probs = torch.stack(prediction_probs).cpu()\n","    real_values = torch.stack(real_values).cpu()\n","    return lyrics_texts, predictions, prediction_probs, real_values"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8UhCCvB2M3p2","executionInfo":{"status":"ok","timestamp":1623315560520,"user_tz":-120,"elapsed":17448,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"fcc525ef-7213-40f4-b5f2-c8d76de0b12f"},"source":["y_lyrics_texts, y_pred, y_pred_probs, y_test = get_predictions(\n","  model,\n","  test_data_loader\n",")"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8heZSh1jM5eg","executionInfo":{"status":"ok","timestamp":1623315560521,"user_tz":-120,"elapsed":19,"user":{"displayName":"Martin Böckling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd1hNZwxLCphvyM-5JVW54XXL2r4S5ISzVZrmw=s64","userId":"11063855120566531958"}},"outputId":"a8c98012-1427-45d2-aa7c-2fab3001fd82"},"source":["class_names = ['negative', 'neutral', 'positive']\n","\n","print(classification_report(y_test, y_pred, target_names=class_names))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    negative       0.59      0.64      0.61       741\n","     neutral       0.47      0.50      0.48       657\n","    positive       0.61      0.53      0.57       771\n","\n","    accuracy                           0.56      2169\n","   macro avg       0.56      0.55      0.55      2169\n","weighted avg       0.56      0.56      0.56      2169\n","\n"],"name":"stdout"}]}]}